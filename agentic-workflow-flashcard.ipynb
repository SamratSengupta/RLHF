{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17f381a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-00b721dfe598>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAzureOpenAI\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_evaluator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEvaluatorType\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mlangchain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchains\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLLMChain\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'langchain'"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "import re\n",
    "import os\n",
    "\n",
    "from langchain import AzureOpenAI\n",
    "from langchain.evaluation import load_evaluator, EvaluatorType\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "from langgraph.graph import Graph, Node, Edge\n",
    "from langgraph.core import ExecutionContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4397ff0e",
   "metadata": {},
   "source": [
    "#### Initialize GPT instances ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69707e0b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AzureOpenAI' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-0a76dd2f1160>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Create instances for GPT-3.5 and GPT-4\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m gpt_3_5_instance = AzureOpenAI(\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mapi_key\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mazure_openai_key\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mapi_base\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mazure_openai_endpoint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'AzureOpenAI' is not defined"
     ]
    }
   ],
   "source": [
    "azure_openai_key = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "azure_openai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "azure_openai_api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "\n",
    "# Create instances for GPT-3.5 and GPT-4\n",
    "gpt_3_5_instance = AzureOpenAI(\n",
    "    api_key=azure_openai_key,\n",
    "    api_base=azure_openai_endpoint,\n",
    "    api_version=azure_openai_api_version,\n",
    "    deployment_id=\"gpt-3.5-turbo\"\n",
    ")\n",
    "\n",
    "gpt_4_instance = AzureOpenAI(\n",
    "    api_key=azure_openai_key,\n",
    "    api_base=azure_openai_endpoint,\n",
    "    api_version=azure_openai_api_version,\n",
    "    deployment_id=\"gpt-4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e614ebb4",
   "metadata": {},
   "source": [
    "####    Create PDF Extractor   ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba0e9150",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PDFExtractor:\n",
    "    def __init__(self, pdf_path):\n",
    "        self.pdf_path = pdf_path\n",
    "\n",
    "    def extract_text(self):\n",
    "        with open(self.pdf_path, 'rb') as file:\n",
    "            reader = PyPDF2.PdfReader(file)\n",
    "            text = \"\"\n",
    "            for page in reader.pages:               \n",
    "                text += page.extract_text()\n",
    "        return text\n",
    "\n",
    "    def preprocess_text(self, text):\n",
    "        text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces and newlines\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d11cc493",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = \"data/defining nursing_2003.pdf\"\n",
    "extractor = PDFExtractor(pdf_path)\n",
    "raw_text = extractor.extract_text()\n",
    "preprocessed_text = extractor.preprocess_text(raw_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852f6881",
   "metadata": {},
   "source": [
    "#### Create Flashcard Generator ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc165fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlashcardGenerator:\n",
    "    def __init__(self, llm_chain):\n",
    "        self.llm_chain = llm_chain\n",
    "\n",
    "    def generate_flashcards(self, text, feedback=None):\n",
    "        prompt = f\"\"\"You are a highly intelligent educational assistant. Generate detailed and comprehensive flashcards from the following text. Ensure that each flashcard contains a well-structured question and a thorough answer. \n",
    "                     Use the following text to create flashcards:\n",
    "                     {text}\"\"\"\n",
    "        if feedback:\n",
    "            prompt += f\" Incorporate the following feedback into the flashcards: {feedback}\"\n",
    "        response = self.llm_chain.run(prompt)\n",
    "        flashcards = response.strip().split(\"\\n\\n\")\n",
    "        return [{\"question\": fc.split(\":\")[0].strip(), \"answer\": fc.split(\":\")[1].strip()} for fc in flashcards if \":\" in fc]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0349672c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the FlashcardGenerator with the GPT-3.5 instance\n",
    "flashcard_generator = FlashcardGenerator(gpt_3_5_instance)\n",
    "initial_flashcards = flashcard_generator.generate_flashcards(preprocessed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1738ba49",
   "metadata": {},
   "source": [
    "#### langchain critic to evaluate/criticise generator ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315bb183",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LangChainCritic:\n",
    "    def __init__(self, llm_chain):\n",
    "        self.llm_chain = llm_chain\n",
    "        self.evaluator = load_evaluator(EvaluatorType.QA)\n",
    "\n",
    "    def evaluate(self, question, answer):\n",
    "        evaluation = self.evaluator.evaluate(question, answer)\n",
    "        score = evaluation['score']\n",
    "        feedback = self.generate_feedback(evaluation)\n",
    "        return score, feedback\n",
    "\n",
    "    def generate_feedback(self, evaluation):\n",
    "        feedback = []\n",
    "        if evaluation['missing']:\n",
    "            feedback.append(f\"Missing: {evaluation['missing']}\")\n",
    "        if evaluation['superfluous']:\n",
    "            feedback.append(f\"Superfluous: {evaluation['superfluous']}\")\n",
    "        if evaluation['inaccuracy']:\n",
    "            feedback.append(f\"Inaccuracy: {evaluation['inaccuracy']}\")\n",
    "        if evaluation['clarity']:\n",
    "            feedback.append(f\"Clarity: {evaluation['clarity']}\")\n",
    "        if evaluation['completeness']:\n",
    "            feedback.append(f\"Completeness: {evaluation['completeness']}\")\n",
    "        return \" \".join(feedback)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e797e5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LangChainCritic with the GPT-4 instance\n",
    "langchain_critic = LangChainCritic(gpt_4_instance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc49a8cf",
   "metadata": {},
   "source": [
    "#### Flashcard refiner ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06682888",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlashcardRefiner:\n",
    "    def __init__(self, generator, critic, iterations=10):\n",
    "        self.generator = generator\n",
    "        self.critic = critic\n",
    "        self.iterations = iterations\n",
    "\n",
    "    def refine_flashcards(self, flashcards):\n",
    "        for i in range(self.iterations):\n",
    "            refined_flashcards = []\n",
    "            for flashcard in flashcards:\n",
    "                question, answer = flashcard['question'], flashcard['answer']\n",
    "                score, feedback = self.critic.evaluate(question, answer)\n",
    "                improved_flashcard = self.generator.generate_flashcards(question, feedback=feedback)[0]\n",
    "                refined_flashcards.append(improved_flashcard)\n",
    "            flashcards = refined_flashcards\n",
    "            print(f\"Iteration {i+1} completed\")\n",
    "        return flashcards\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec718eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "refiner = FlashcardRefiner(flashcard_generator, langchain_critic)\n",
    "refined_flashcards = refiner.refine_flashcards(initial_flashcards)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a26bfb",
   "metadata": {},
   "source": [
    "#### Human Validator ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b745e25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HumanValidator:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def validate_flashcards(self, flashcards):\n",
    "        for flashcard in flashcards:\n",
    "            print(f\"Question: {flashcard['question']}\")\n",
    "            print(f\"Answer: {flashcard['answer']}\")\n",
    "            feedback = input(\"Is this flashcard satisfactory? (yes/no): \")\n",
    "            flashcard['status'] = 'Approved' if feedback.lower() == 'yes' else 'Needs Improvement'\n",
    "        return [fc for fc in flashcards if fc['status'] == 'Approved']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffc9e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### create own flashcards and validate ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1182dd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "validator = HumanValidator()\n",
    "approved_flashcards = validator.validate_flashcards(refined_flashcards)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0ba5d1",
   "metadata": {},
   "source": [
    "#### workflow mgmt with lang graph #### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74f006e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define nodes\n",
    "extract_text_node = Node(\n",
    "    id=\"extract_text\",\n",
    "    run=lambda context: extractor.extract_text(),\n",
    "    outputs=[\"raw_text\"]\n",
    ")\n",
    "\n",
    "preprocess_text_node = Node(\n",
    "    id=\"preprocess_text\",\n",
    "    run=lambda context: extractor.preprocess_text(context[\"raw_text\"]),\n",
    "    inputs=[\"raw_text\"],\n",
    "    outputs=[\"preprocessed_text\"]\n",
    ")\n",
    "\n",
    "generate_flashcards_node = Node(\n",
    "    id=\"generate_flashcards\",\n",
    "    run=lambda context: flashcard_generator.generate_flashcards(context[\"preprocessed_text\"]),\n",
    "    inputs=[\"preprocessed_text\"],\n",
    "    outputs=[\"initial_flashcards\"]\n",
    ")\n",
    "\n",
    "evaluate_flashcards_node = Node(\n",
    "    id=\"evaluate_flashcards\",\n",
    "    run=lambda context: [langchain_critic.evaluate(fc['question'], fc['answer']) for fc in context[\"initial_flashcards\"]],\n",
    "    inputs=[\"initial_flashcards\"],\n",
    "    outputs=[\"evaluations\"]\n",
    ")\n",
    "\n",
    "refine_flashcards_node = Node(\n",
    "    id=\"refine_flashcards\",\n",
    "    run=lambda context: refiner.refine_flashcards(context[\"initial_flashcards\"]),\n",
    "    inputs=[\"initial_flashcards\", \"evaluations\"],\n",
    "    outputs=[\"refined_flashcards\"]\n",
    ")\n",
    "\n",
    "validate_flashcards_node = Node(\n",
    "    id=\"validate_flashcards\",\n",
    "    run=lambda context: validator.validate_flashcards(context[\"refined_flashcards\"]),\n",
    "    inputs=[\"refined_flashcards\"],\n",
    "    outputs=[\"approved_flashcards\"]\n",
    ")\n",
    "\n",
    "# Define edges to connect nodes\n",
    "edges = [\n",
    "    Edge(from_node=\"extract_text\", to_node=\"preprocess_text\"),\n",
    "    Edge(from_node=\"preprocess_text\", to_node=\"generate_flashcards\"),\n",
    "    Edge(from_node=\"generate_flashcards\", to_node=\"evaluate_flashcards\"),\n",
    "    Edge(from_node=\"evaluate_flashcards\", to_node=\"refine_flashcards\"),\n",
    "    Edge(from_node=\"refine_flashcards\", to_node=\"validate_flashcards\")\n",
    "]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eaf4842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and compile the graph\n",
    "graph = Graph(nodes=[extract_text_node, preprocess_text_node, generate_flashcards_node, evaluate_flashcards_node, refine_flashcards_node, validate_flashcards_node], edges=edges)\n",
    "\n",
    "# Execution context\n",
    "context = ExecutionContext(inputs={\"pdf_path\": pdf_path})\n",
    "result = graph.run(context)\n",
    "\n",
    "approved_flashcards = result[\"approved_flashcards\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
